{
  "cells": [
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "# Microsoft Azure AutoML Exercise"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "### Purpose and Challenge\nThe purpose of this notebook is fo the user to build and deploy a machine learning application using Azure Machine Learning Service which is in preview. \n\nThis Notebook include incomplete codes that require you to fullfill the lines in order to make it to work properly. This exercise will help you to exercise and practice the knowledge explained in the previous example. \n"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "## 1. Acquire and Prepare Data\n\nFor this exercise, we are using a simple dataset named \"House price prediction\". You can find it here: https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Housing.csv .This is a simple dataset. \nWe have it in a txt file in the same folder. We will use pandas to read the file into a Dataframe, which we will use it later to train the model.\n\nthe filename is 'iris.data.txt'. The delimiter used will be ','."
    },
    {
      "metadata": {
        "trusted": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\ndata = pd.read_csv('Housing.csv', dtype = {\n                                            'driveway':'category',\n                                            'recroom':'category',\n                                            'fullbase':'category',\n                                            'gashw':'category',\n                                            'airco':'category', \n                                            'prefarea': 'category'}\n                  )\n#take a look at the data\ndata.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data.dtypes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Convert the categorical columns to numeric ones. As we see from dataframe, there are only binary values(yes/no), so we can translate them into 0/1"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for col in data.columns:\n    if data[col].dtype.name == 'category':\n        data[col] = pd.Series(np.where(data[col] == 'yes', 1, 0))\ndata.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We will go straight into model training, without doing EDA(exploratory data analysis) or applying any feature engineering techniques."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2.Automated ML\n\nImport Azure ML libs for automated ML."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import logging, os, random, time\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport azureml.core\nfrom azureml.core.experiment import Experiment\nfrom azureml.core.workspace import Workspace\nfrom azureml.train.automl import AutoMLConfig\nfrom azureml.train.automl.run import AutoMLRun\nfrom azureml.widgets import RunDetails\nfrom azureml.core.model import Model\nfrom azureml.pipeline.core import PipelineRun\nfrom azureml.core.run import Run",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Provide your machine learning workspace credentials to run workspace. we will need to perform a Microsoft MFA. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "subscription_id ='the subscription id'\nresource_group ='Resource group name'\nworkspace_name = 'the workspace name'\nworkspace_region = \"workspace region\"\n\n#load an existring workspace\ntry:\n    #write here the code\nexcept:\n    print('Workspace not found. TOO MANY ISSUES!!!')\n    \n    \n#if you have not already created a workspace you can create it with a simple line of code\n\n#loading an already created workspace.\nws = Workspace.from_config()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ws.get_details()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create the Experiment by assigning a name to it. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\npath_project_folder = './'\n\n\noutput = dict()\n\noutput['SDK version'] = azureml.core.VERSION\noutput['Subscription ID'] = ws.subscription_id\noutput['Workspace Name'] = ws.name\noutput['Resource Group'] = ws.resource_group\noutput['Location'] = ws.location\n\npd.DataFrame(data = output, index=['']).T",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Splitting the data into training, validation and test set\n\nWe will use train_test_split from scikit-learn "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n#split the data into train, validation and test sets. make sure you not include the target and id columns into these sets. \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Helper\nfrom azureml.telemetry import set_diagnostics_collection\nset_diagnostics_collection(send_diagnostics = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 3.AutoML Configuration "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#fill the parameters\nautoml_config = AutoMLConfig(task=,\n                             primary_metric = ,\n                             iteration_timeout_minutes =5,\n                             iterations=10,\n                             max_cores_per_iteration = 1,\n                             preprocess=, \n                             X = , \n                             y = , \n                             X_valid = , \n                             y_valid = ,\n                             auto_blacklist = True, \n                             #n_cross_validation= 3\n                             debug_log = 'house_logs.log',\n                             verbosity=logging.ERROR,\n                             path = path_project_folder, \n                             whitelist_models = []\n                            )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#you should create an experiment and submit it to be executed\nexperiment_name = 'write a name for your experiment'\nexperiment = # create an experiment \nlocal_run = #submit an experiment",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#show the details of the execution\nRunDetails(local_run).show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 4.Get the best Model \n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#write down the code to retrieve the best model.\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Test the best model with test data that we splitted before."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n\ny_pred = fitted.predict(X_test)\nprint('r2_score :',r2_score(y_pred, y_test))\nprint('root mean squared error :  ', np.sqrt(mean_squared_error(y_pred, y_test)))\nprint('mean absolute error : ', mean_absolute_error(y_pred, y_test))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "test_pred = plt.scatter(y_test, y_pred, color='b')\ntest_test = plt.scatter(y_test, y_test, color='g')\nplt.legend((test_pred, test_test), ('prediction', 'truth'), loc='upper left', fontsize=8)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 5. Deploy the model \nAs now we have succesfully trained the model, we are ready to deploy it. \n\n1. we need to register the model on our workspace\n2. Create a score script for Web Service\n2. create a yaml file for the environment\n3. Create a Container Image\n4. Deploy as a Web Service"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Model Registration"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Here write the code to register the best model. There are 2 ways of doing it, it is up to you to select the way. \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create a score script for Web Service"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile score.py\n# Scoring Script\nimport json\nimport numpy as np\nimport os\nimport pickle\nfrom sklearn.externals import joblib\nfrom sklearn.linear_model import LogisticRegression\n\nfrom azureml.core.model import Model\n\nimport azureml.train.automl\n\ndef init():\n    global model\n    # retreive the path to the model file using the model name\n    model_path = Model.get_model_path('AutoMLaa94670e5best')\n    print(model_path)\n    model = joblib.load(model_path)\n    \n\ndef run(raw_data):\n    # grab and prepare the data\n    data = (np.array(json.loads(raw_data)['data'])).reshape(1,-1)\n    # make prediction\n    y_hat = model.predict(data)\n    return json.dumps(y_hat.tolist())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### create yaml file with conda environment and dependencies."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.conda_dependencies import CondaDependencies\n\nmyenv = # complete the code to create the conda environment with library dependencies and pip. \nconda_env_file_name = 'my_conda_env.yml'\nmyenv.save_to_file('.',conda_env_file_name)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "with open(\"my_conda_env.yml\",\"r\") as f:\n    print(f.read())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create a Container Image"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile docker_steps.dockerfile\nRUN apt-get update && \\\n    apt-get upgrade -y && \\\n    apt-get install -y build-essential gcc g++ python-dev unixodbc unixodbc-dev",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "docker_file_name = \"docker_steps.dockerfile\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.image import Image, ContainerImage\n#create the image container which will later deployed as a service.\n\n#specify runtime, the execution script the docker filename, conda env config file, optional tags and descriptiong\n\nimage.wait_for_creation(show_output=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Deploy as a Web Service\n\nFirst, write the web service configurations \nLast deploy the web service"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.webservice import Webservice\nfrom azureml.core.webservice import AciWebservice\n\naciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n                                               memory_gb = 1, \n                                                tags = {'ml': 'priceprediction',\n                                                       'type':'automl'},\n                                                description = 'house price prediction exercise'\n                                               )\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "aci_service_name = 'write a name for you service.'\naci_service = #write the code to deploy the service from image.\n\naci_service.wait_for_deployment(True)\nprint(aci_service.state)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(aci_service.get_logs())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Test the service"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import requests\nimport json\n\n# send a random row from the test set to score\n#random_index = np.random.randint(0, len(X_train)-1)\ninput_data = \"{\\\"data\\\": \" + str(X_test.values.tolist()) + \"}\" #str(list(X_train[0].reshape(1,-1)[0])) + \"}\"\n\nheaders = {'Content-Type':'application/json'}\n\n# for AKS deployment you'd need to the service key in the header as well\n# api_key = service.get_key()\n# headers = {'Content-Type':'application/json',  'Authorization':('Bearer '+ api_key)} \n\nresp = requests.post(aci_service.scoring_uri, input_data, headers=headers)\n\nprint(\"POST to url\", aci_service.scoring_uri)\nprint(\"input data:\", input_data)\nprint(\"label:\", y_test[1:2])\nprint(\"prediction:\", resp.text)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "### Remove a service created. \n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Cancel an experiment \n\nFirst, retrieve the information from your workspace"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "_experiment = ws.experiments['<experiment name>']\nrun_id = '<you have to check on azure portal/ your workspace/ Experiment / running experiment and get Run_id>'\n\nexp_running = Run(experiment=_experiment, run_id=run_id)\nexp_running.cancel()",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "celltoolbar": "Attachments"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}