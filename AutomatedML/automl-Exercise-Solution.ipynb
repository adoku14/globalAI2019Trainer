{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Microsoft Azure AutoML Exercise"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Purpose and Challenge\nThe purpose of this notebook is fo the user to build and deploy a machine learning application using Azure Machine Learning Service which is in preview. \n\nThis Notebook include incomplete codes that require you to fullfill the lines in order to make it to work properly. This exercise will help you to exercise and practice the knowledge explained in the previous example. \n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 1. Acquire and Prepare Data\n\nFor this exercise, we are using a simple dataset named \"House price prediction\". You can find it here: https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Housing.csv .This is a simple dataset. \nWe have it in a txt file in the same folder. We will use pandas to read the file into a Dataframe, which we will use it later to train the model.\n\nthe filename is 'iris.data.txt'. The delimiter used will be ','."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\ndata = pd.read_csv('Housing.csv', dtype = {\n                                            'driveway':'category',\n                                            'recroom':'category',\n                                            'fullbase':'category',\n                                            'gashw':'category',\n                                            'airco':'category', \n                                            'prefarea': 'category'}\n                  )\n#take a look at the data\ndata.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data.dtypes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for col in data.columns:\n    if data[col].dtype.name == 'category':\n        data[col] = pd.Series(np.where(data[col] == 'yes', 1, 0))\ndata.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We will go straight into model training, without doing EDA(exploratory data analysis) or applying any feature engineering techniques."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2.Automated ML\n\nImport Azure ML libs for automated ML."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import logging, os, random, time\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport azureml.core\nfrom azureml.core.experiment import Experiment\nfrom azureml.core.workspace import Workspace\nfrom azureml.train.automl import AutoMLConfig\nfrom azureml.train.automl.run import AutoMLRun\nfrom azureml.widgets import RunDetails\nfrom azureml.core.model import Model\nfrom azureml.pipeline.core import PipelineRun\nfrom azureml.core.run import Run",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Provide your machine learning workspace credentials to run workspace. we will need to perform a Microsoft MFA. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "subscription_id =''\nresource_group =''\nworkspace_name = ''\nworkspace_region = \"\"\n\n#ws = Workspace.create(name = workspace_name, subscription_id=subscription_id, resource_group=resource_group, location=workspace_region, exist_ok=True) #to create a new workspace\n\n#loading an already created workspace.\ntry:\n    ws = Workspace(workspace_name=workspace_name, subscription_id=subscription_id, resource_group=resource_group)\n    print('Workspace configuration succeeded. You are all set!')\nexcept:\n    print('Workspace not found. TOO MANY ISSUES!!!')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ws.get_details()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create the Experiment by assigning a name to it. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "experiment_name = 'predict_house_price'\npath_project_folder = './'\n\nexperiment = Experiment(ws, experiment_name)\noutput = dict()\n\noutput['SDK version'] = azureml.core.VERSION\noutput['Subscription ID'] = ws.subscription_id\noutput['Workspace Name'] = ws.name\noutput['Resource Group'] = ws.resource_group\noutput['Location'] = ws.location\noutput['Experiment Name'] = experiment_name\n\npd.DataFrame(data = output, index=['']).T",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Splitting the data into training, validation and test set\n\nWe will use train_test_split from scikit-learn "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nX = data[[x for x in data.columns if x not in ['price', 'id']]] #removing the target column and id as should not be included in training set.\ntarget = data['price'].values\nX_train, X_valid, y_train, y_valid = train_test_split(X, target, test_size=0.3, random_state=42)\nX_test = X_valid.iloc[-10:]\ny_test = y_valid[-10:]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train.shape, X_valid.shape, X_test.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Helper\nfrom azureml.telemetry import set_diagnostics_collection\nset_diagnostics_collection(send_diagnostics = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 3.AutoML Configuration "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "automl_config = AutoMLConfig(task='regression',\n                             primary_metric = 'r2_score',\n                             iteration_timeout_minutes =5,\n                             iterations=10,\n                             max_cores_per_iteration = 1,\n                             preprocess=False, \n                             X = X_train, \n                             y = y_train, \n                             X_valid = X_valid, \n                             y_valid = y_valid,\n                             auto_blacklist = True, \n                             #n_cross_validation= 3\n                             debug_log = 'house_logs.log',\n                             verbosity=logging.ERROR,\n                             path = path_project_folder, \n                             whitelist_models = ['LightGBM', 'ElasticNet', 'SGDRegressor', 'RandomForestRegressor', 'XGBoostRegressor']\n                            )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "local_run = experiment.submit(automl_config, show_output=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "RunDetails(local_run).show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 4.Get the best Model \n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "best_model, fitted = local_run.get_output()\nprint(best_model, fitted)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Test the best model with test data that we splitted before."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n\ny_pred = fitted.predict(X_test)\nprint('r2_score :',r2_score(y_pred, y_test))\nprint('root mean squared error :  ', np.sqrt(mean_squared_error(y_pred, y_test)))\nprint('mean absolute error : ', mean_absolute_error(y_pred, y_test))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "test_pred = plt.scatter(y_test, y_pred, color='b')\ntest_test = plt.scatter(y_test, y_test, color='g')\nplt.legend((test_pred, test_test), ('prediction', 'truth'), loc='upper left', fontsize=8)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 5. Deploy the model \nAs now we have succesfully trained the model, we are ready to deploy it. \n\n1. we need to register the model on our workspace\n2. Create a score script for Web Service\n2. create a yaml file for the environment\n3. Create a Container Image\n4. Deploy as a Web Service"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Model Registration"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# model = Model.register(ws, model_name='housepriceprediction', model_path='model.pkl', \n#                        description='house price prediction model')\n\nmodel = local_run.register_model(description='best fitter model elastic search standard scaler for housing price prediction', tags = {'ml': 'price_prediction', 'type':'automl'})\nprint(local_run.model_id)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model.id",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create a score script for Web Service"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile score.py\n# Scoring Script\nimport json\nimport numpy as np\nimport os\nimport pickle\nfrom sklearn.externals import joblib\nfrom sklearn.linear_model import LogisticRegression\n\nfrom azureml.core.model import Model\n\nimport azureml.train.automl\n\ndef init():\n    global model\n    # retreive the path to the model file using the model name\n    model_path = Model.get_model_path('AutoMLaa94670e5best')\n    print(model_path)\n    model = joblib.load(model_path)\n    \n\ndef run(raw_data):\n    # grab and prepare the data\n    data = (np.array(json.loads(raw_data)['data'])).reshape(1,-1)\n    # make prediction\n    y_hat = model.predict(data)\n    return json.dumps(y_hat.tolist())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### create yaml file with conda environment and dependencies."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.conda_dependencies import CondaDependencies\n\nmyenv = CondaDependencies.create(conda_packages=['numpy', 'scikit-learn', 'pandas'], pip_packages=['azureml-train-automl'])\n\nconda_env_file_name = 'my_conda_env.yml'\nmyenv.save_to_file('.',conda_env_file_name)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "with open(\"my_conda_env.yml\",\"r\") as f:\n    print(f.read())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create a Container Image"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile docker_steps.dockerfile\nRUN apt-get update && \\\n    apt-get upgrade -y && \\\n    apt-get install -y build-essential gcc g++ python-dev unixodbc unixodbc-dev",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "docker_file_name = \"docker_steps.dockerfile\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.image import Image, ContainerImage\n#specify runtime, the execution script the docker filename, conda env config file, optional tags and descriptiong\nimage_config = ContainerImage.image_configuration(runtime='python', \n                                                  execution_script='score.py', \n                                                 docker_file = docker_file_name, \n                                                 conda_file= conda_env_file_name, \n                                                 tags = None,\n                                                 description='Container image for deploying housing price prediction model!')\n\nimage = Image.create(name='housingpriceprediction', \n                    models = [model], \n                    image_config = image_config,\n                    workspace= ws)\n\nimage.wait_for_creation(show_output=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Deploy as a Web Service\n\nFirst, write the web service configurations \nLast deploy the web service"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.webservice import Webservice\nfrom azureml.core.webservice import AciWebservice\n\naciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n                                               memory_gb = 1, \n                                                tags = {'ml': 'priceprediction',\n                                                       'type':'automl'},\n                                                description = 'house price prediction exercise'\n                                               )\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "aci_service_name = 'automlhousepriceprediction'\naci_service = Webservice.deploy_from_image(deployment_config=aciconfig, \n                                          image = image, \n                                          name = aci_service_name,\n                                          workspace=ws)\n\naci_service.wait_for_deployment(True)\nprint(aci_service)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(aci_service.get_logs())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Test the service"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import requests\nimport json\n\n# send a random row from the test set to score\n#random_index = np.random.randint(0, len(X_train)-1)\ninput_data = \"{\\\"data\\\": \" + str(X_test.iloc[0].values.tolist()) + \"}\" #str(list(X_train[0].reshape(1,-1)[0])) + \"}\"\n\nheaders = {'Content-Type':'application/json'}\n\n# for AKS deployment you'd need to the service key in the header as well\n# api_key = service.get_key()\n# headers = {'Content-Type':'application/json',  'Authorization':('Bearer '+ api_key)} \n\nresp = requests.post(aci_service.scoring_uri, input_data, headers=headers)\n\nprint(\"POST to url\", aci_service.scoring_uri)\nprint(\"input data:\", input_data)\nprint(\"label:\", y_test[0])\nprint(\"prediction:\", resp.text)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "### Remove a service created. \nservice.delete()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Cancel an experiment \n\nFirst, retrieve the information from your workspace"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "_experiment = ws.experiments['<experiment name>']\nrun_id = '<you have to check on azure portal/ your workspace/ Experiment / running experiment and get Run_id>'\n\nexp_running = Run(experiment=_experiment, run_id=run_id)\nexp_running.cancel()",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}