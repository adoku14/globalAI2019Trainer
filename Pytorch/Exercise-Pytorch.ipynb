{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Digit Recognition Task\n",
    "If this is your first time running a notebook - welcome!! Notebooks are awesome because they let us play around and experiment\n",
    "with code with near-instant feedback. Some pointers:\n",
    "1. To execute a cell, click on it and hit SHIFT-Enter\n",
    "2. Once something is executed, the variables are in memory - inspect them!\n",
    "\n",
    "## Getting Started\n",
    "This first cell imports the necessary libraries so we can get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.onnx as onnx\n",
    "from PIL import Image, ImageOps\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "#packages for cloud \n",
    "import json\n",
    "import time\n",
    "import azureml\n",
    "from azureml.core.model import Model\n",
    "from azureml.core import Workspace, Run, Experiment\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.train.dnn import PyTorch\n",
    "from azureml.core.image import ContainerImage, Image\n",
    "from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data\n",
    "\n",
    "we will load Cifar10 dataset from Pytorch datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                            #resize the image\n",
    "                            #convert to tensor.\n",
    "])\n",
    "\n",
    "training_data = #code for reading MNIST training data.\n",
    "validation_data = # code for reading MNIST validation/testing data. \n",
    "\n",
    "training_loader = torch.utils.data.DataLoader()\n",
    "validation_loader = torch.utils.data.DataLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look into the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def im_convert(img_tensor):\n",
    "    img_tensor = img_tensor.cpu().clone().detach().numpy()\n",
    "    img_tensor = img_tensor.transpose(1, 2, 0)\n",
    "    img_tensor = img_tensor * np.array((1,1,1))\n",
    "#     img_tensor = img_tensor.clip(0,1)\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(training_loader)\n",
    "images, labels = dataiter.next()\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "\n",
    "for i in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 10, i+1)\n",
    "    plt.imshow(im_convert(images[i]))\n",
    "    ax.set_title(labels[i].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Models\n",
    "Now that we have some data it's time to start picking models we think might work. This is where the science part of data-science comes in: we guess and then check if our assumptions were right. Imagine models like water pipes that have to distribute water to 10 different hoses depending on 784 knobs. These 784 knobs represent the individual pixels in the digit and the 10 hoses at the end represent the actual number (or at least the index of the one with the most water coming out of it). Our job now is to pick the plumbing in between.\n",
    "\n",
    "The next three cells represent three different constructions in an increasingly more complex order:\n",
    "\n",
    "1. The first is a simple linear model,\n",
    "2. The second is a 3 layer Neural Network,\n",
    "3. The third is a full convolutional neural network\n",
    "4. and the last is a full Conv neural network with padding\n",
    "\n",
    "While it is out of the scope of this tutorial to fully explain how they work, just imagine they are basically plumbing with internal knobs that have to be tuned to produce the right water pressure at the end to push the most water out of the right\n",
    "index. As you go down each cell the plumbing and corresponding internal knobs just get more complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a simple linear model. You assignment is to build complex model based on this one.\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(n_in, n_out)\n",
    "        self.linear = nn.Linear(n_in, n_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.softmax(self.linear(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the code to build the named Neural Network models. as a reference follow the example of Linear model above. \n",
    "Tip: you can use F.relu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `learning_rate` basically specifies how fast the algorithm will learn the model parameters. Right now you're probably thinking \"let's set it to fifty million #amirite?\" The best analogy for why this is a bad idea is golf. I'm a terrible golfist (is that right?) so I don't really know anything - but pretend you are trying to sink a shot (again sorry) but can only hit the ball the same distance every time. Easy right? Hit it the exact length from where you are to the hole! Done! Now pretend you don't know where the hole is but just know the general direction. Now the distance you choose actually matters. If it is too long a distance you'll miss the hole, and then when you hit it back you'll overshoot again. If the distance is too small then it will take forever to get there but for sure you'll eventually get it in. Basically you have to guess what the right distance per shot should be and then try it out. That is basically what the learning rate does for finding the \"hole in one\" for the right parameters (ok, I'm done with the golf stuff).\n",
    "\n",
    "Below there are three things that make this all work:\n",
    "1. **The Model** - this is the function we're making that takes in the digit vector and should return the right number\n",
    "2. **The Cost Function** (sometimes called the loss function). I know I promised I was done with golf but I lied. Remember how I said in our screwy golf game you knew the general direction of the hole? The cost function tells us the distance to the hole - when it's zero we're there! In actual scientific terms, the cost function tells us how bad the model is at getting the right answer. As we take shots you should see the cost function decreasing. If this does not happen then something is wrong. At this point I would change the shot distance (or `learning_rate`) to something smaller and try again. If that doesn't work maybe change the model!\n",
    "3. **The Optimizer** - this part is the bit that actually changes the model parameters. It has a sense for the direction we should be shooting and updates all of the internal numbers inside the model to find the best internal knobs to predict the right digits. In this case I am using the Binary Cross Entropy cost function because, well, I know it works. There are a ton of different cost functions you can choose from that fit a variety of different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where to run\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "\n",
    "#initialize the model you want to use. \n",
    "\n",
    "#declare the loss function. hint: you can use cross entropy loss.\n",
    "\n",
    "#continue the code to initialize the optimizer. \n",
    "optimizer = torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss_history = []\n",
    "running_loss_correct = []\n",
    "val_running_loss_history = []\n",
    "val_running_correct_hostory = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0.0\n",
    "    \n",
    "    val_running_loss = 0.0\n",
    "    val_running_correct = 0.0\n",
    "    \n",
    "    for xxx,xxx in xxx:\n",
    "        #zero the gradients\n",
    "        #use the model to make prediction. \n",
    "        #calculate the loss/error\n",
    "        #backward the loss\n",
    "        #and update the weights.\n",
    "        \n",
    "        \n",
    "        _, preds = torch.max(output, 1) #preds is the index of max value for that image\n",
    "        running_correct += torch.sum(preds == labels.data)\n",
    "        running_loss += loss\n",
    "        \n",
    "    for xxx, xxx in xxx: #validation data\n",
    "        \n",
    "        #predict the validation data. \n",
    "        #calculate the loss/error\n",
    "        \n",
    "        _, val_preds = torch.max(val_output, 1)\n",
    "        val_running_loss += val_loss\n",
    "        val_running_correct += torch.sum(val_preds==val_labels.data)\n",
    "    \n",
    "    #training scores\n",
    "    epoch_loss = running_loss/len(training_loader)\n",
    "    acc_epoch = running_correct.float()/len(training_loader)\n",
    "    running_loss_history.append(epoch_loss)\n",
    "    running_loss_correct.append(acc_epoch)\n",
    "    \n",
    "    #validation scores\n",
    "    val_epoch_loss = val_running_loss/len(validation_loader)\n",
    "    val_acc_epoch = val_running_correct.float()/len(validation_loader)\n",
    "    val_running_loss_history.append(val_epoch_loss)\n",
    "    val_running_correct_hostory.append(val_acc_epoch)\n",
    "    \n",
    "    \n",
    "    print('training: loss {:0.4f} acc {:0.4f}, validation: loss {:0.4f} acc {:0.4f}'.format(epoch_loss, acc_epoch, val_epoch_loss, val_acc_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the plots below. Think about what do you understand from them. is the model underfitting/overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(running_loss_history, label='training loss') \n",
    "plt.plot(val_running_loss_history, label='validation loss') \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(running_loss_correct, label='training accuracy') \n",
    "plt.plot(val_running_correct_hostory, label='validation accuracy') \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Saving the Model\n",
    "Every framework is different - in this case PyTorch let's us save the model (which you remember is just a big matrix `W` and a vector `b`) to an internal format as well as to the ONNX format. These can then be loaded up as an asset to a program that is executed every time you need to recognize a digit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy variable to traverse graph\n",
    "x = torch.randint(255, (1, 28*28), dtype=torch.float).to(device) / 255\n",
    "onnx.export(model, x, 'model.onnx')\n",
    "print('Saved onnx model to model.onnx')\n",
    "\n",
    "# saving PyTorch Model Dictionary\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "print('Saved PyTorch Model to model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. To the cloud\n",
    "Make sure you are running python 3.6.  If not, please follow the step below. \n",
    "\n",
    "Click on the \"Project Settings\"\n",
    "\n",
    "![Project Setings](https://raw.githubusercontent.com/sethjuarez/pytorchintro/master/images/project_settings.png)\n",
    "\n",
    "Next, select the \"Environments\" tab, choose \"Python 3.6\", and finally select the corresponding `requirements.txt` file.\n",
    "\n",
    "![Settings](https://raw.githubusercontent.com/sethjuarez/pytorchintro/master/images/settings.png)\n",
    "\n",
    "After those steps you should be good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Setting up Azure Machine Learning service\n",
    "The first thing you need to do is create an Azure Machine Learning workspace. There are [docs](https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-get-started#create-a-workspace) on how to do that. If you're a command line type person, I have an [example](https://github.com/sethjuarez/workspacestarter) of how you can set it up using the Azure CLI. Once you've set the project up fill in the appropriate settings for your workspace by uncommenting the first the code to write out the config file. Once the config file has been written out, you can load the workspace programmatically like I've done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = '' \n",
    "resource_group = ''\n",
    "workspace_name = ''\n",
    "\n",
    "try:\n",
    "    ws = # write down the code to load the workspace we already created in previous session.\n",
    "    ws.write_config()\n",
    "except:\n",
    "    print('The workspace {} not found'.format(workspace_name))\n",
    "    \n",
    "# once you run the above code once, you can use the written config\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Cloud Compute\n",
    "Next we need to define a compute target for your experiment. Since this is a brand new workspace, feel free to change the name of your cluster (I called my `racer`). The code below tries to get a reference to my cluster but if it doesn't exist, it creates it for me. If you're creating a cluster this might take a bit of time. Also, please turn these off when you're done (in fact consider setting the `min_nodes` to 0 so the cluster turns off automatically if it's idle for too long) - I don't want you to get an unexpected bill. \n",
    "vm_size = 'STANDARD_NC6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target_name = ''\n",
    "\n",
    "try:\n",
    "    compute = # declare compute target\n",
    "    print('Found existing compute target \"{}\"'.format(cluster))\n",
    "except:\n",
    "    #if not exist, we have to create one.\n",
    "    print('Creating new compute target \"{}\"...'.format(cluster))\n",
    "    compute_config = # the configuration for compute target\n",
    "    compute = #create compute target\n",
    "    compute.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to Experiment\n",
    "Once our compute target has been set up it's time to package up our tiny notebook from last time into a single script that a remote compute environment can run. I've taken the time to [do that for you](train.py). In fact, if you look at the file you will see all of the exact same concepts we learned from the previous notebook (it's almost exactly the same but I have added additional things to make it easier to pass things into the script).\n",
    "\n",
    "In AzureML service there is a concept of an experiment. For every experiment you can have multiple runs. In this case I'm using an `Estimator` object that defines how the experiment should run.\n",
    "\n",
    "### Don't read this if you don't care what we do in the background\n",
    "In the background the estimator is basically a definition of sorts for a docker image that will house your experiment. The best part about all of this is that irrespective of what you use for your experiment (a crazy custom version of TensorFlow or something) it should always run - it's a container after all. It's pretty slick.\n",
    "\n",
    "### Back to the regular stuff\n",
    "Once we submit our estimator to be run on AzureML service, it copies the contents of the current directory and packages them up to run in our new container (well, it will upload everything with the exception of anything you put describe in the [.amlignore](https://github.com/sethjuarez/pytorchintro/blob/master/.amlignore) file).\n",
    "\n",
    "Notice also that since I'm using `argparse` I can specify external parameters to the trainin script as part of the estimator definition.\n",
    "\n",
    "Let's run the next three lines to see what happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare the experiment. \n",
    "exp = Experiment(ws, '')\n",
    "\n",
    "script_params = {\n",
    "    '--lr':0.01,\n",
    "    '--batch': 100,\n",
    "    '--epochs':5,\n",
    "    '--model':'cnn'\n",
    "}\n",
    "\n",
    "# declare the estimator, \n",
    "estimator = PyTorch()\n",
    "\n",
    "#submit the experiment for execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out a list of files created and saved locally. We are interested to the model file .pth\n",
    "run.get_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Register the model. use the name = 'PyTorchMNIST'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#register the model. Same implementation as we did at previous session\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Conda Dependencies, Image Container, Web Service\n",
    "as the have register the model, now we are ready to create the image and deploy our model as a web service. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure the conda dependencies and write down to file.\n",
    "\n",
    "with open('pytorchmnist.yml','w') as f:\n",
    "    print('Writing out {}'.format('pytorchmnist.yml'))\n",
    "    f.write(myenv.serialize_to_string())\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_config = # image configuration.\n",
    "\n",
    "image = # image deployment code \n",
    "image.wait_for_creation(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_name = ''\n",
    "\n",
    "#checking whether the service name already exist as a service. if yes delete.\n",
    "svcs = [svc for svc in Webservice.list(ws) if svc.name==service_name]\n",
    "if len(svcs) == 1:\n",
    "    print('Deleting prior {} deployment'.format(service_name))\n",
    "    svcs[0].delete()\n",
    "    \n",
    "\n",
    "\n",
    "# create service\n",
    "aciconfig = AciWebservice.deploy_configuration(#fill the parameters)\n",
    "\n",
    "service = #fill the code to deploy the image\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have the option of pushing the image to ACI or even a workspace Kubernetes cluster.\n",
    "\n",
    "Sometimes things go wrong....... If it does for you run the code below to see the actual [logs](deploy.log)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('deploy.log','w') as f:\n",
    "    f.write(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. running the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, Y = digits[57435]\n",
    "X = X * 255\n",
    "plt.imshow(255 - X.reshape(28,28), cmap='gray')\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a string representation of the image we will POST to the endpoint\n",
    "image_str = ','.join(map(str, X.int().tolist()))\n",
    "print(image_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "service_url = service.scoring_uri\n",
    "print(service_url)\n",
    "r = requests.post(service_url, json={'image': image_str })\n",
    "r.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
